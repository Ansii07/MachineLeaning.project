{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaa9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ae5e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>leader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600000e+18</td>\n",
       "      <td>Removal of Article 370 ended corruption in J&amp;amp;K. SC should dismiss all the application ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>amit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.600000e+18</td>\n",
       "      <td>Invasion can be quite mischievous. Do people use such colors for common use? Love Jihad...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>amit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.600000e+18</td>\n",
       "      <td>Supreme Court is going to start hearing on Article 370 &amp;amp; 35 A. Would Supreme Court of India ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>amit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.600000e+18</td>\n",
       "      <td>Article 370 was Abrogated and many  Progressive Central Laws were extended to JK but on the grou...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>amit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.600000e+18</td>\n",
       "      <td>POK liya bjp ne ?\\nAksai chin liya?\\nBhai Congress ke Negative points pata hai.. Bjp ke posit...</td>\n",
       "      <td>0.542424</td>\n",
       "      <td>-0.034545</td>\n",
       "      <td>Negative</td>\n",
       "      <td>amit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0      Tweet Id  \\\n",
       "0             0             0         0.0  1.600000e+18   \n",
       "1             1             1         1.0  1.600000e+18   \n",
       "2             2             2         2.0  1.600000e+18   \n",
       "3             3             3         3.0  1.600000e+18   \n",
       "4             4             4         4.0  1.600000e+18   \n",
       "\n",
       "                                                                                                  Text  \\\n",
       "0        Removal of Article 370 ended corruption in J&amp;K. SC should dismiss all the application ...   \n",
       "1           Invasion can be quite mischievous. Do people use such colors for common use? Love Jihad...   \n",
       "2  Supreme Court is going to start hearing on Article 370 &amp; 35 A. Would Supreme Court of India ...   \n",
       "3  Article 370 was Abrogated and many  Progressive Central Laws were extended to JK but on the grou...   \n",
       "4     POK liya bjp ne ?\\nAksai chin liya?\\nBhai Congress ke Negative points pata hai.. Bjp ke posit...   \n",
       "\n",
       "   Subjectivity  Polarity     score leader  \n",
       "0      0.000000  0.000000   Neutral   amit  \n",
       "1      0.700000  0.060000  Positive   amit  \n",
       "2      0.000000  0.000000   Neutral   amit  \n",
       "3      0.375000  0.250000  Positive   amit  \n",
       "4      0.542424 -0.034545  Negative   amit  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Shubham\\\\Desktop\\\\Leader Merge File.csv\")\n",
    "df.head(136000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb90a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1.0\n",
      "  (1, 7)\t1.0\n",
      "  (2, 7)\t1.0\n",
      "  (3, 0)\t0.7071067811865476\n",
      "  (3, 6)\t0.7071067811865476\n",
      "  (4, 5)\t1.0\n",
      "  (5, 4)\t1.0\n",
      "  (6, 2)\t1.0\n",
      "  (7, 3)\t1.0\n",
      "  (8, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF model using Tfidf vectorizer function.\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_model = vectorizer.fit_transform(df)\n",
    "print(tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e755383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.        ]\n",
      " [0.70710678 0.         0.         0.         0.         0.\n",
      "  0.70710678 0.        ]\n",
      " [0.         0.         0.         0.         0.         1.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         1.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# print the full sparse matrix\n",
    "print(tfidf_model.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8995ab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>score</th>\n",
       "      <th>leader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unnamed  tweet   id  text  subjectivity  polarity     score  leader\n",
       "0  0.000000    0.0  0.0   0.0           0.0       0.0  0.000000     1.0\n",
       "1  0.000000    0.0  0.0   0.0           0.0       0.0  0.000000     1.0\n",
       "2  0.000000    0.0  0.0   0.0           0.0       0.0  0.000000     1.0\n",
       "3  0.707107    0.0  0.0   0.0           0.0       0.0  0.707107     0.0\n",
       "4  0.000000    0.0  0.0   0.0           0.0       1.0  0.000000     0.0\n",
       "5  0.000000    0.0  0.0   0.0           1.0       0.0  0.000000     0.0\n",
       "6  0.000000    0.0  1.0   0.0           0.0       0.0  0.000000     0.0\n",
       "7  0.000000    0.0  0.0   1.0           0.0       0.0  0.000000     0.0\n",
       "8  0.000000    1.0  0.0   0.0           0.0       0.0  0.000000     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_model.toarray(), columns = vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de58c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  Tweet Id      Text  Subjectivity  Polarity     score  \\\n",
      "0         0.000000  0.000000  0.574548      0.000000  0.772861  0.269408   \n",
      "1         0.000000  0.595587  0.000000      0.498282  0.435455  0.455379   \n",
      "2         0.319968  0.000000  0.311864      0.640047  0.559344  0.000000   \n",
      "3         0.527331  0.000000  0.000000      0.527422  0.000000  0.482010   \n",
      "4         0.000000  0.000000  0.000000      1.000000  0.000000  0.000000   \n",
      "...            ...       ...       ...           ...       ...       ...   \n",
      "136081    0.000000  0.000000  0.744487      0.000000  0.667637  0.000000   \n",
      "136082    0.382726  0.000000  0.373033      0.382792  0.000000  0.349833   \n",
      "136083    0.000000  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
      "136084    1.000000  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
      "136085    0.000000  0.000000  0.000000      0.753777  0.000000  0.000000   \n",
      "\n",
      "          leader  \n",
      "0       0.000000  \n",
      "1       0.000000  \n",
      "2       0.278991  \n",
      "3       0.459798  \n",
      "4       0.000000  \n",
      "...          ...  \n",
      "136081  0.000000  \n",
      "136082  0.667423  \n",
      "136083  0.000000  \n",
      "136084  0.000000  \n",
      "136085  0.657130  \n",
      "\n",
      "[136086 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Shubham\\\\Desktop\\\\Leader Merge File.csv\")\n",
    "\n",
    "# Extract the text data\n",
    "text_data = data['Text']\n",
    "\n",
    "# Remove missing values and non-string values\n",
    "text_data = text_data.dropna().astype(str)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=7)  # Specify the maximum number of features\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Manually specify column names\n",
    "column_names = ['Unnamed: 0', 'Tweet Id', 'Text', 'Subjectivity', 'Polarity','score', 'leader']\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame with manual column names\n",
    "df_tfidf = pd.DataFrame.sparse.from_spmatrix(X, columns=column_names)\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c75665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d595e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9545e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = pd.read_csv(r\"C:\\Users\\Shubham\\Desktop\\Amit Shah for tfidf.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b69140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "Corpus['Text'].dropna(inplace=True)\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus['Text'] = [str(entry).lower() for entry in Corpus['Text']]\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus['Text']= [word_tokenize(entry) for entry in Corpus['Text']]\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(Corpus['Text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1016ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['Text'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d25ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
